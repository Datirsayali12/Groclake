{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install groclake"
      ],
      "metadata": {
        "id": "OwLusgT_ne5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeVihiBRFOr1"
      },
      "outputs": [],
      "source": [
        "!pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ groclake==0.1.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1.**Create a .env File:** In your project directory, create a .env file and add your configuration variables in KEY=VALUE format."
      ],
      "metadata": {
        "id": "1bNst0P9Nk1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example .env file\n",
        "\n",
        "# MySQL Configuration\n",
        "MYSQL_HOST_PROD=127.0.0.1\n",
        "MYSQL_PORT_PROD=3306\n",
        "MYSQL_USER_PROD=root\n",
        "MYSQL_PASSWORD_PROD=password\n",
        "MYSQL_DB_PROD=example_db\n",
        "\n",
        "# Elasticsearch Configuration\n",
        "ES_HOST=127.0.0.1\n",
        "ES_PORT=9200\n",
        "ES_API_KEY=es_api_key\n",
        "\n",
        "# Redis Configuration\n",
        "REDIS_HOST=127.0.0.1\n",
        "REDIS_PORT=6379\n",
        "\n",
        "# Optional: GCP Credentials\n",
        "# GCP_CREDENTIALS=/path/to/your/gcp_credentials.json\n"
      ],
      "metadata": {
        "id": "LyXuv6IDz4H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#setp 2: create config.py file\n",
        "\n",
        "In your Config.py file, use the dotenv package to load the .env file and assign the configuration values.\n",
        "\n",
        "Example config file"
      ],
      "metadata": {
        "id": "dTgd6ULrHPoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "\n",
        "class Config:\n",
        "    MYSQL_CONFIG = {\n",
        "        \"host\": os.getenv(\"MYSQL_HOST_PROD\"),\n",
        "        \"port\": int(os.getenv(\"MYSQL_PORT_PROD\")),\n",
        "        \"username\": os.getenv(\"MYSQL_USER_PROD\"),\n",
        "        \"password\": os.getenv(\"MYSQL_PASSWORD_PROD\"),\n",
        "        \"database\": os.getenv(\"MYSQL_DB_PROD\"),\n",
        "    }\n",
        "\n",
        "    # Elasticsearch connection\n",
        "    api_key = os.getenv(\"ES_API_KEY\")\n",
        "    encoded_api_key = base64.b64encode(api_key.encode(\"utf-8\")).decode(\"utf-8\")\n",
        "\n",
        "    ES_CONFIG = {\n",
        "        \"host\": os.getenv(\"ES_HOST\"),\n",
        "        \"port\": int(os.getenv(\"ES_PORT\")),\n",
        "        \"headers\": {\n",
        "            \"Authorization\": f\"ApiKey {encoded_api_key}\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Redis Configuration\n",
        "    REDIS_CONFIG = {\n",
        "        \"host\": os.getenv(\"REDIS_HOST\"),  # 127.0.0.1\n",
        "        \"port\": int(os.getenv(\"REDIS_PORT\")),  # 6379\n",
        "    }\n",
        "\n",
        "    # Optional: GCP Credentials for storage and pipeline execution\n",
        "    # GCP_CREDENTIALS = os.getenv(\"GCP_CREDENTIALS\", \"path_to_your_gcp_credentials.json\")"
      ],
      "metadata": {
        "id": "eQnDEf1xGf1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 3: Import Required Modules  \n",
        "The **Datalake** class from groclake.datalake provides the basic functionalities for managing data pipelines.\n",
        "\n",
        "The **Config** module contains the configuration details for MySQL, Elasticsearch (ES), and Redis."
      ],
      "metadata": {
        "id": "dZJFsA65Fmc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groclake.datalake import Datalake\n",
        "from config import Config"
      ],
      "metadata": {
        "id": "Nf0HBlEkFeKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 4:Define DatalakeConnection Class\n",
        "The DatalakeConnection class extends Datalake and adds specific data connections to a pipeline."
      ],
      "metadata": {
        "id": "Ge2A7K7YIIZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatalakeConnection(Datalake):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Inherit from Datalake class\n",
        "\n",
        "        # Define the configuration for each connection\n",
        "        MYSQL_CONFIG = Config.MYSQL_CONFIG\n",
        "        MYSQL_CONFIG['connection_type'] = 'sql'\n",
        "\n",
        "        ES_CONFIG = Config.ES_CONFIG\n",
        "        ES_CONFIG['connection_type'] = 'es'\n",
        "\n",
        "        REDIS_CONFIG = Config.REDIS_CONFIG\n",
        "        REDIS_CONFIG['connection_type'] = 'redis'\n",
        "\n",
        "        # Create and add connections to the pipeline\n",
        "        self.test_pipeline = self.create_pipeline(name=\"test_pipeline\")\n",
        "        self.test_pipeline.add_connection(name=\"sql_connection\", config=MYSQL_CONFIG)\n",
        "        self.test_pipeline.add_connection(name=\"es_connection\", config=ES_CONFIG)\n",
        "        self.test_pipeline.add_connection(name=\"redis_connection\", config=REDIS_CONFIG)\n",
        "\n",
        "        # Execute all connections at once\n",
        "        self.execute_all()\n",
        "\n",
        "        # Initialize connections\n",
        "        self.connections = {\n",
        "            \"sql_connection\": self.get_connection(\"sql_connection\"),\n",
        "            \"es_connection\": self.get_connection(\"es_connection\"),\n",
        "            \"redis_connection\": self.get_connection(\"redis_connection\"),\n",
        "        }\n",
        "\n",
        "    def get_connection(self, connection_name):\n",
        "        \"\"\"\n",
        "        Returns a connection by name from the pipeline.\n",
        "        \"\"\"\n",
        "        return self.test_pipeline.get_connection_by_name(connection_name)\n"
      ],
      "metadata": {
        "id": "uNEBr0BHIHRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inheriting from Datalake:** The DatalakeConnection class inherits from the Datalake class, so it can use the methods defined in the parent class (like creating pipelines, adding connections, and executing tasks).\n",
        "\n",
        "**Configuring Connections:** For each connection (MySQL, Elasticsearch, Redis), we fetch the connection details from Config. The connection types are added to distinguish between SQL databases (sql), Elasticsearch (es), and Redis (redis).\n",
        "\n",
        "**Creating the Pipeline:** We create a pipeline called test_pipeline using the create_pipeline method from the Datalake class. This pipeline will manage all the data connections.\n",
        "\n",
        "**Adding Connections:** We add each connection to the pipeline by specifying a name and configuration. Each connection is uniquely identified by its name (sql_connection, etc.).\n",
        "\n",
        "**Executing Connections:** Once all connections are added, we use the execute_all method to execute all connections concurrently using threads.\n",
        "\n",
        "**Storing Connections:** The connections dictionary stores the connections, which can later be accessed by name (e.g., sql_connection)."
      ],
      "metadata": {
        "id": "8kxyhww-IpZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 5: Intialize DatalakeConnection class"
      ],
      "metadata": {
        "id": "yTx0LLXwqGd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GROCLAKE_API_KEY'] = userdata.get('groclake_api_key')\n",
        "os.environ['GROCLAKE_ACCOUNT_ID'] = userdata.get('groclake_account_id')"
      ],
      "metadata": {
        "id": "xqEtgHQHcs1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datalake_connection = DatalakeConnection()"
      ],
      "metadata": {
        "id": "-NMiBRkAGK1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create an instance of the DatalakeConnection class. When the class is instantiated, it automatically creates the pipeline, adds the connections (MySQL, Elasticsearch, Redis), and executes them concurrently."
      ],
      "metadata": {
        "id": "hMpgq8kWKo_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 6:Accessing a Specific Connection"
      ],
      "metadata": {
        "id": "MO2a1so7KvVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing a specific connection (MySQL connection in this case)\n",
        "mysql_connection = datalake_connection.connections[\"sql_connection\"]\n",
        "print(\"MySQL Connection:\", mysql_connection)\n",
        "\n",
        "es_connection = datalake_connection.connections[\"es_connection\"]\n",
        "print(\"Elasticsearch Connection:\", es_connection)\n",
        "\n",
        "redis_connection = datalake_connection.connections[\"redis_connection\"]\n",
        "print(\"Redis Connection:\", redis_connection)"
      ],
      "metadata": {
        "id": "EtxImz5DMomW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44d50a5-a478-47bc-94ba-b47bdbcad76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MySQL Connection: <groclake.datalake.connection.SQLConnection object at 0x7b166dc5b410>\n",
            "Elasticsearch Connection: <groclake.datalake.connection.ESConnection object at 0x7b166dc5ae10>\n",
            "Redis Connection: <groclake.datalake.connection.RedisConnection object at 0x7b166dc58910>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE of MySQL Connection\n",
        "\n"
      ],
      "metadata": {
        "id": "8o3oIIi3fBW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INSERT DATA\n",
        "def insert_user(name, status):\n",
        "    query = \"INSERT INTO user_details (user_id, name, status) VALUES (%s, %s, %s)\"\n",
        "    params = (\"1234\", name, status)\n",
        "    mysql_connection.write(query, params)\n",
        "    return True\n",
        "\n",
        "\n",
        "#FETCH DATA\n",
        "def get_user_info(user_id):\n",
        "    query = \"SELECT * FROM user_details WHERE user_id = %s\"\n",
        "    params = (user_id,)\n",
        "    response = mysql_connection.read(query, params)\n",
        "    return response"
      ],
      "metadata": {
        "id": "M0UGKmo3e-rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use of Elasticsearch connection"
      ],
      "metadata": {
        "id": "tnz-vEF0j0Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE\n",
        "\n",
        "# Define the write query\n",
        "write_query = {\n",
        "    \"index\": \"users\",  # Index name\n",
        "    \"body\": {\n",
        "        \"user_id\": \"123\",\n",
        "        \"name\": \"Alice\",\n",
        "        \"role\": \"Engineer\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "write_response = es_connection.write(write_query)\n",
        "print(\"Write Response:\", write_response)\n",
        "\n",
        "\n",
        "#READ\n",
        "read_query = {\n",
        "    \"index\": \"users\",\n",
        "    \"body\": {\n",
        "        \"query\": {\n",
        "            \"match_all\": {}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "document_count = es_connection.read(read_query)\n",
        "print(\"Total Documents:\", document_count)"
      ],
      "metadata": {
        "id": "UKb1u0iVT8GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#USE of Redis Connection\n"
      ],
      "metadata": {
        "id": "q7nHqvO9kJgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE\n",
        "key = \"user:1000:name\"\n",
        "value = \"John Doe\"\n",
        "cache_ttl = 3600  # TTL of 1 hour\n",
        "\n",
        "redis_connection.set(key, value, cache_ttl)\n",
        "print(f\"Set value for {key}: {value}\")\n",
        "\n",
        "#READ\n",
        "key = \"user:1000:name\"\n",
        "value = redis_connection.get(key)\n",
        "print(f\"Got value for {key}: {value.decode('utf-8')}\")"
      ],
      "metadata": {
        "id": "Eyptt0VUkNMN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}